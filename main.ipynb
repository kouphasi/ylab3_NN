{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koumi\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 5\n",
    "n_output = 5\n",
    "n_hidden = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_input, n_output, n_hidden):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(n_input,n_hidden)\n",
    "        self.l2 = torch.nn.Linear(n_hidden,n_output)\n",
    "\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.l1(x)\n",
    "        x2 = self.relu(x1)\n",
    "        x3 = self.l2(x2)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(n_input, n_output, n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('l1.weight', Parameter containing:\n",
      "tensor([[-0.1824,  0.0148, -0.2221,  0.1687, -0.3811],\n",
      "        [ 0.3278, -0.3251, -0.3556, -0.2826,  0.2025],\n",
      "        [-0.1652,  0.1674, -0.3796, -0.2713, -0.1642],\n",
      "        [-0.0879, -0.3412,  0.2928, -0.1055,  0.1436],\n",
      "        [ 0.3162,  0.0833,  0.1223,  0.4317, -0.2017],\n",
      "        [ 0.1417, -0.1990,  0.3196,  0.3572, -0.4123],\n",
      "        [ 0.3818,  0.2136,  0.1949,  0.1841,  0.3718],\n",
      "        [-0.0590, -0.3782, -0.1283, -0.3150,  0.0296],\n",
      "        [-0.0835, -0.2399, -0.0407,  0.4237, -0.0353],\n",
      "        [ 0.0142, -0.0697,  0.0703,  0.3985,  0.2735],\n",
      "        [ 0.1587,  0.0972,  0.1054,  0.1728, -0.0578],\n",
      "        [-0.4156, -0.2766,  0.3817,  0.0267, -0.3623],\n",
      "        [ 0.0705,  0.3695, -0.4226, -0.3011, -0.1781],\n",
      "        [ 0.0180, -0.1043, -0.0491, -0.4360,  0.2094],\n",
      "        [ 0.3925,  0.2734, -0.3167, -0.3605,  0.1857],\n",
      "        [ 0.0100,  0.1833, -0.4370, -0.0267,  0.3154],\n",
      "        [ 0.2075,  0.0163,  0.0879, -0.0423, -0.2459],\n",
      "        [-0.1690, -0.2723,  0.3715,  0.2461,  0.1564],\n",
      "        [-0.3429,  0.3451,  0.1402,  0.3094, -0.1759],\n",
      "        [ 0.0948,  0.4367,  0.3008,  0.3587, -0.0939],\n",
      "        [ 0.3407, -0.3503,  0.0387, -0.2518, -0.1043],\n",
      "        [-0.1145,  0.0335,  0.4070,  0.2214, -0.0019],\n",
      "        [ 0.3175, -0.2292,  0.2305, -0.0415, -0.0778],\n",
      "        [ 0.0524, -0.3426,  0.0517,  0.1504,  0.3823],\n",
      "        [-0.1392,  0.1610,  0.4470, -0.1918,  0.4251],\n",
      "        [-0.2220,  0.1971,  0.1752,  0.1249,  0.3537],\n",
      "        [-0.1807,  0.1175,  0.0025, -0.3364, -0.1086],\n",
      "        [-0.2987,  0.1977,  0.0402,  0.0438, -0.1357],\n",
      "        [ 0.0022, -0.1391,  0.1285,  0.4343,  0.0677],\n",
      "        [-0.1981, -0.2732,  0.0342, -0.3318, -0.3361],\n",
      "        [-0.2911, -0.1519,  0.0331,  0.3080,  0.1732],\n",
      "        [ 0.3426, -0.2808,  0.0377, -0.3975,  0.2565],\n",
      "        [ 0.0932,  0.4326, -0.3181,  0.3586,  0.3775],\n",
      "        [ 0.3616,  0.0638,  0.4066,  0.2987,  0.3337],\n",
      "        [-0.0291, -0.3432, -0.0056,  0.0839, -0.3046],\n",
      "        [-0.2565, -0.4288, -0.1568,  0.3896,  0.0765],\n",
      "        [-0.0273,  0.0180,  0.2789, -0.3949, -0.3451],\n",
      "        [-0.1487, -0.2574,  0.2307,  0.3160, -0.4339],\n",
      "        [-0.3795, -0.4355,  0.1687,  0.3599, -0.3467],\n",
      "        [-0.2070,  0.1423, -0.2920,  0.3799,  0.1043],\n",
      "        [-0.1245,  0.0290,  0.1394, -0.1581, -0.3465],\n",
      "        [ 0.0030,  0.0081,  0.0090, -0.0653,  0.2871],\n",
      "        [-0.1248, -0.0433,  0.1839, -0.2815,  0.1197],\n",
      "        [-0.0989,  0.2145, -0.2426,  0.0165,  0.0438],\n",
      "        [-0.3598, -0.3252,  0.1715, -0.1302,  0.2656],\n",
      "        [-0.4418, -0.2211, -0.3684,  0.1786, -0.0130],\n",
      "        [-0.0834, -0.0744, -0.3496,  0.1268,  0.0111],\n",
      "        [-0.3086,  0.1683, -0.0090, -0.4325,  0.2406],\n",
      "        [ 0.2392, -0.0843, -0.3088,  0.0180,  0.3375],\n",
      "        [ 0.4094, -0.3376, -0.2020,  0.3482,  0.2186],\n",
      "        [ 0.2768, -0.2226,  0.3853, -0.3676, -0.0215],\n",
      "        [ 0.0093,  0.0751, -0.3375,  0.4103,  0.4395],\n",
      "        [-0.3088,  0.0165, -0.2382,  0.4288,  0.2494],\n",
      "        [ 0.2634,  0.1443, -0.0445,  0.2518,  0.0076],\n",
      "        [-0.1631,  0.2309,  0.1403, -0.1159, -0.1226],\n",
      "        [-0.3955, -0.1226, -0.1812, -0.2438, -0.4039],\n",
      "        [ 0.3503, -0.3997,  0.4440, -0.2346, -0.0344],\n",
      "        [ 0.3648,  0.1475, -0.1277, -0.3600, -0.1828],\n",
      "        [ 0.3601, -0.1689,  0.3727, -0.0770, -0.0570],\n",
      "        [ 0.1785, -0.0657, -0.0038,  0.3097,  0.1495],\n",
      "        [-0.0178,  0.1703,  0.3895,  0.1127, -0.1311],\n",
      "        [ 0.1465, -0.0391, -0.3496, -0.1727,  0.2034],\n",
      "        [ 0.0147,  0.1650, -0.2618,  0.4228, -0.1866],\n",
      "        [ 0.0954, -0.2185, -0.2157,  0.2003, -0.1248],\n",
      "        [-0.2836, -0.1828,  0.3261,  0.2692,  0.2722],\n",
      "        [-0.3817,  0.2106,  0.1117, -0.3007,  0.0141],\n",
      "        [ 0.0894, -0.2416, -0.1887,  0.3648, -0.0361],\n",
      "        [-0.0047, -0.2830, -0.2674,  0.4117,  0.1664],\n",
      "        [-0.0708,  0.2724, -0.2128, -0.3901, -0.4440],\n",
      "        [ 0.1817, -0.1744,  0.2746,  0.3820,  0.1473],\n",
      "        [ 0.3842, -0.1030,  0.3897, -0.2132, -0.0587],\n",
      "        [ 0.2972, -0.2317,  0.3413,  0.1096, -0.0088],\n",
      "        [ 0.3827,  0.3355, -0.1839,  0.0434,  0.0521],\n",
      "        [ 0.3663,  0.2513,  0.3621,  0.2726, -0.3891],\n",
      "        [ 0.2971, -0.1188,  0.3588,  0.2814, -0.2614],\n",
      "        [-0.0471,  0.0668,  0.1278, -0.4142,  0.0200],\n",
      "        [ 0.2330,  0.2525,  0.2200,  0.0707, -0.4290],\n",
      "        [ 0.2943, -0.3521, -0.2628,  0.0052,  0.1362],\n",
      "        [ 0.2598, -0.0628, -0.2302, -0.0385,  0.1465],\n",
      "        [-0.2516, -0.3884,  0.2135, -0.2960, -0.2517],\n",
      "        [ 0.3710, -0.2947, -0.3629,  0.3399, -0.2134],\n",
      "        [ 0.0290,  0.4455, -0.1785,  0.4166,  0.3553],\n",
      "        [ 0.3454,  0.1326, -0.2016,  0.2816, -0.3063],\n",
      "        [-0.2605, -0.2156,  0.1934,  0.0616,  0.2845],\n",
      "        [ 0.2939,  0.0261,  0.2607, -0.3232, -0.4274],\n",
      "        [-0.3643,  0.2468,  0.4112, -0.1237,  0.2474],\n",
      "        [-0.3196, -0.0084, -0.0027, -0.1295, -0.2168],\n",
      "        [ 0.2098, -0.0390, -0.0886,  0.3107, -0.3396],\n",
      "        [ 0.2920,  0.3972, -0.2747, -0.4237,  0.0622],\n",
      "        [-0.3401,  0.1870, -0.3567, -0.3490,  0.1210],\n",
      "        [-0.1146, -0.3959,  0.1745,  0.1580,  0.0603],\n",
      "        [ 0.2922, -0.1796,  0.4082, -0.3408,  0.4032],\n",
      "        [ 0.3323, -0.3978, -0.0397, -0.2406,  0.4400],\n",
      "        [-0.0187,  0.2634,  0.3866, -0.3449,  0.2719],\n",
      "        [-0.3890, -0.1208, -0.1803, -0.4183, -0.4212],\n",
      "        [-0.4312, -0.3459, -0.2499, -0.1474,  0.2502],\n",
      "        [-0.0719, -0.4428, -0.3248,  0.3210, -0.4364],\n",
      "        [-0.2200, -0.4047,  0.2406,  0.3057,  0.0391],\n",
      "        [-0.2248, -0.1084,  0.0261,  0.1874,  0.0077],\n",
      "        [-0.2085,  0.0217,  0.0137,  0.0042,  0.1945],\n",
      "        [-0.1685,  0.0282,  0.0019,  0.1888, -0.2738],\n",
      "        [-0.3496, -0.3640,  0.1879,  0.3558,  0.4436],\n",
      "        [ 0.1597, -0.0912,  0.0824, -0.4422,  0.0516],\n",
      "        [-0.1476, -0.0340,  0.2569, -0.1539, -0.3388],\n",
      "        [ 0.0270, -0.1245, -0.2085, -0.1366, -0.2536],\n",
      "        [ 0.3925,  0.0307, -0.2374,  0.2851,  0.0692],\n",
      "        [ 0.2567,  0.3448,  0.4420, -0.1159,  0.0133],\n",
      "        [-0.2591,  0.4080,  0.1423, -0.0740,  0.1121],\n",
      "        [ 0.4437,  0.1821,  0.2172,  0.4129,  0.0191],\n",
      "        [ 0.0021,  0.1110, -0.4133,  0.1564, -0.0034],\n",
      "        [-0.0214,  0.0257,  0.3961,  0.1283, -0.4051],\n",
      "        [ 0.4143,  0.2727,  0.2257,  0.1845,  0.0436],\n",
      "        [-0.2469,  0.2867, -0.3342, -0.2705,  0.0011],\n",
      "        [-0.3470,  0.4057,  0.4443,  0.2229,  0.2730],\n",
      "        [-0.4332,  0.3860,  0.0785, -0.2825, -0.3123],\n",
      "        [ 0.1078,  0.2696, -0.1198, -0.1087, -0.0864],\n",
      "        [-0.4184,  0.3218, -0.0385, -0.4104, -0.3353],\n",
      "        [ 0.1403, -0.4298,  0.3150, -0.3693, -0.0153],\n",
      "        [ 0.1319, -0.2109, -0.2904, -0.0473,  0.0805],\n",
      "        [-0.0795,  0.2006,  0.2342,  0.1795,  0.4131],\n",
      "        [-0.2715, -0.3583,  0.1102,  0.0812,  0.4300],\n",
      "        [ 0.4336,  0.1919,  0.2649,  0.2036, -0.0334],\n",
      "        [-0.4187, -0.1771, -0.3797,  0.3177, -0.2417],\n",
      "        [-0.3526, -0.0587,  0.3042,  0.1955,  0.1636],\n",
      "        [-0.0272, -0.4089, -0.2651, -0.3782, -0.1334],\n",
      "        [ 0.3083, -0.2965, -0.1151,  0.4390,  0.3073],\n",
      "        [ 0.1626,  0.2841, -0.0909, -0.2401,  0.2259],\n",
      "        [ 0.1206, -0.1387,  0.3450, -0.3187, -0.0094]], requires_grad=True))\n",
      "('l1.bias', Parameter containing:\n",
      "tensor([ 0.3616,  0.1439, -0.3510,  0.0728, -0.0640,  0.1847,  0.2519, -0.3165,\n",
      "        -0.1473,  0.3716, -0.3261, -0.1014, -0.1489, -0.1094, -0.0616,  0.2568,\n",
      "         0.2795, -0.1603,  0.0521, -0.4149, -0.1689, -0.0418, -0.0162,  0.0816,\n",
      "         0.0245, -0.1330,  0.3220, -0.1465,  0.3571,  0.2640, -0.0099, -0.1649,\n",
      "         0.2753,  0.0049, -0.2432,  0.2422,  0.0345,  0.4291, -0.4398,  0.1090,\n",
      "        -0.4087, -0.1991, -0.0440,  0.3633, -0.1859, -0.2597, -0.0292, -0.0546,\n",
      "        -0.3545,  0.0127,  0.2374, -0.1924, -0.3552, -0.3164,  0.2125, -0.0273,\n",
      "         0.3244, -0.0404,  0.0087,  0.3717,  0.1463, -0.3166,  0.0826, -0.0128,\n",
      "        -0.2942,  0.3849,  0.2043, -0.1886, -0.3989,  0.1893, -0.3849,  0.0904,\n",
      "        -0.2795,  0.0747,  0.0891,  0.2184, -0.1336, -0.0059, -0.2397,  0.0364,\n",
      "         0.0268,  0.3896,  0.4311, -0.0796, -0.1897, -0.0582, -0.2957, -0.2053,\n",
      "        -0.2915, -0.2896,  0.3494,  0.1209, -0.1852, -0.4408,  0.1951, -0.2769,\n",
      "        -0.4426, -0.4368,  0.1432,  0.0925,  0.0052, -0.4292,  0.1454, -0.3810,\n",
      "         0.0606,  0.0507, -0.3089, -0.0126, -0.3498,  0.3722, -0.1764,  0.1967,\n",
      "        -0.3873,  0.1413, -0.4264, -0.0533,  0.1076, -0.0315,  0.2633,  0.3534,\n",
      "        -0.3215,  0.3204, -0.3162, -0.2894, -0.0889,  0.4061,  0.3191, -0.0354],\n",
      "       requires_grad=True))\n",
      "('l2.weight', Parameter containing:\n",
      "tensor([[-4.8820e-02, -3.4533e-02, -3.5028e-02,  4.9001e-02, -6.5054e-04,\n",
      "         -2.0405e-02, -7.1639e-02,  7.2462e-03,  5.4623e-02,  5.5808e-02,\n",
      "          7.6260e-03,  8.1236e-02, -2.1853e-02,  6.8672e-02,  4.9400e-02,\n",
      "          7.8076e-02,  4.5534e-02, -7.9568e-02,  4.3268e-02, -6.3857e-02,\n",
      "         -5.9198e-02, -6.2036e-02, -4.0929e-02, -7.9389e-02,  7.5497e-02,\n",
      "         -3.7236e-02,  5.7844e-02,  7.9245e-02,  5.6051e-02,  6.5730e-02,\n",
      "          2.2348e-03, -8.6867e-02,  5.3965e-02, -7.4470e-02,  2.2860e-02,\n",
      "         -3.6879e-02,  5.6615e-02,  5.8977e-02, -4.6057e-03, -3.0786e-02,\n",
      "          6.8404e-02, -2.7818e-02, -6.8054e-02, -5.7144e-02, -8.4596e-02,\n",
      "          6.5391e-02,  6.6396e-02, -2.2503e-02,  3.8996e-02,  5.0326e-02,\n",
      "         -3.5572e-02,  1.5001e-02, -1.5044e-02, -4.2539e-02, -5.5698e-02,\n",
      "         -4.3495e-02, -6.6111e-03, -1.0617e-02, -6.7007e-02, -8.0317e-02,\n",
      "         -1.2028e-02,  3.4307e-02,  2.9367e-02, -6.1894e-02,  4.7672e-02,\n",
      "         -6.1109e-02, -4.2955e-02,  7.2089e-02,  2.2136e-02,  3.2290e-02,\n",
      "         -8.5125e-02, -7.6869e-02, -1.6468e-02,  8.1487e-02, -8.7189e-02,\n",
      "          4.8810e-02, -4.1646e-02, -6.3135e-02,  6.8469e-02, -6.7139e-02,\n",
      "          3.2055e-02, -2.2493e-02,  6.3136e-02, -8.3841e-02,  4.6295e-02,\n",
      "          5.4766e-02,  2.0682e-02,  7.7220e-02,  7.3595e-02,  4.8568e-02,\n",
      "          6.1380e-02,  7.5410e-02,  6.7372e-02,  4.3562e-02, -6.0266e-02,\n",
      "          4.7827e-02, -2.7847e-03,  3.6528e-02, -2.0460e-04,  4.9111e-02,\n",
      "         -7.9266e-02, -5.7809e-02, -2.9906e-02,  7.5578e-02, -5.7008e-02,\n",
      "         -5.4948e-03, -2.8770e-02, -8.3721e-02, -7.8951e-02, -7.2429e-02,\n",
      "         -7.5213e-02, -7.1221e-02, -1.4032e-02,  8.1590e-02, -4.7748e-02,\n",
      "         -3.1096e-02, -3.7377e-02,  1.9620e-02,  5.3406e-02, -4.0485e-02,\n",
      "         -4.1101e-02,  2.8936e-02, -8.2584e-02,  5.2401e-02, -3.4127e-02,\n",
      "          3.9793e-02,  6.8388e-02,  1.9716e-02],\n",
      "        [-8.6123e-02, -2.5917e-02,  7.5409e-02, -8.1545e-02,  7.3774e-02,\n",
      "         -6.7226e-02, -1.9211e-02,  6.1759e-02, -8.3435e-02, -8.1560e-02,\n",
      "         -1.7778e-02, -6.5509e-02, -7.1870e-03,  5.7710e-02,  4.4801e-02,\n",
      "         -8.0449e-02, -2.3172e-02, -6.6995e-02, -5.6216e-02,  4.1493e-02,\n",
      "          1.8161e-02,  8.4061e-02,  3.2754e-02, -6.2722e-02,  2.4139e-02,\n",
      "         -5.8644e-02, -8.3449e-02, -7.5288e-02,  8.3486e-02, -4.2960e-02,\n",
      "          6.7654e-02, -5.8644e-02,  7.9796e-02, -5.2473e-02,  2.5253e-02,\n",
      "         -8.8239e-02, -3.6675e-02, -2.4953e-02, -6.8845e-03, -3.8435e-02,\n",
      "         -2.0621e-02, -8.4300e-03,  6.1282e-02, -8.3815e-02, -6.5663e-02,\n",
      "          3.1942e-02, -1.3557e-02, -1.9962e-02, -4.1114e-03,  8.0659e-02,\n",
      "         -8.4759e-02,  6.5099e-02,  3.9441e-02, -5.2161e-02, -1.8080e-02,\n",
      "         -2.6380e-02, -2.9952e-02, -5.4139e-02,  7.1965e-02,  8.3243e-02,\n",
      "          2.0122e-02,  4.7161e-02,  7.1246e-02,  4.3401e-02,  8.7851e-02,\n",
      "          3.8075e-02, -8.7836e-02,  8.8363e-02,  8.1159e-03, -4.1836e-02,\n",
      "          1.6334e-02, -5.6914e-02, -3.7717e-02,  1.4630e-02, -2.7829e-02,\n",
      "         -6.6109e-02, -3.7804e-03,  8.2857e-02, -2.7540e-04,  1.0636e-02,\n",
      "         -1.5123e-03, -5.4208e-02,  1.1573e-02, -6.3733e-02,  3.8523e-02,\n",
      "          8.4496e-02,  8.5388e-02, -1.9945e-02, -7.8759e-02,  1.4996e-02,\n",
      "          6.5798e-02,  1.6161e-02, -8.4682e-02,  8.5065e-02, -8.2569e-02,\n",
      "          1.8763e-02,  8.3885e-02, -4.6266e-02, -2.0338e-02,  1.7052e-02,\n",
      "         -2.3174e-02,  4.5268e-02,  2.1489e-02, -4.8284e-03, -2.6756e-03,\n",
      "         -3.4413e-02, -1.2402e-02, -6.2752e-02,  8.7734e-02, -9.9764e-03,\n",
      "          2.9827e-02,  3.3543e-02,  5.8254e-02, -2.5755e-02, -6.9643e-02,\n",
      "         -1.1480e-02, -7.4160e-02, -2.7727e-02, -4.4994e-02, -8.7727e-02,\n",
      "          3.7704e-02,  8.6833e-02,  2.0517e-03,  7.0111e-02,  5.8469e-02,\n",
      "          7.2743e-02,  1.0405e-02,  5.7252e-02],\n",
      "        [-6.5428e-02, -8.3967e-02,  2.9251e-02, -4.0960e-02,  8.6899e-02,\n",
      "          1.2430e-02, -2.8477e-02,  7.7010e-02,  8.4672e-02,  6.5623e-02,\n",
      "          5.4392e-02, -2.5306e-02,  4.8860e-02,  2.6276e-02, -3.3379e-02,\n",
      "         -6.2601e-02,  8.8324e-02, -7.7858e-02,  2.0030e-02, -4.2997e-02,\n",
      "         -7.5222e-02, -4.0921e-02, -3.4307e-02,  5.0822e-02, -4.5165e-03,\n",
      "          8.2772e-02,  1.7627e-02,  2.3986e-04,  5.6047e-02, -1.1610e-02,\n",
      "          4.5984e-02,  2.7838e-02, -2.3343e-03, -6.2352e-02,  6.3702e-02,\n",
      "         -6.4327e-02,  3.3964e-02, -8.6989e-02,  9.0828e-03,  3.4649e-03,\n",
      "          3.4941e-02, -5.5995e-02, -7.2743e-02, -2.7200e-02, -4.2567e-02,\n",
      "         -8.1998e-02,  6.4092e-02,  9.3771e-03,  4.1076e-02,  4.2676e-02,\n",
      "         -3.5685e-02, -3.1555e-02, -6.4971e-02,  7.2977e-02,  5.4520e-02,\n",
      "         -1.8101e-02, -2.4153e-02,  7.2632e-02, -2.3732e-02, -3.1350e-02,\n",
      "          2.5074e-02, -3.3080e-02,  2.9337e-04,  6.7002e-02, -6.6107e-02,\n",
      "          5.3179e-02, -4.9578e-02, -2.0095e-02,  4.3839e-02,  1.8322e-02,\n",
      "          5.5312e-02, -2.0862e-02,  7.0468e-02, -6.1808e-02,  2.6428e-02,\n",
      "         -4.4147e-02, -3.5535e-02,  5.9426e-02, -8.6261e-02,  4.5420e-02,\n",
      "          2.7639e-02, -2.6082e-02,  4.9168e-02,  6.9595e-02, -5.5343e-02,\n",
      "          5.6782e-02, -5.7035e-02, -4.4474e-02,  6.6345e-02,  5.4101e-02,\n",
      "          3.9524e-02, -8.0758e-02,  4.4253e-02,  3.3026e-02,  2.6107e-02,\n",
      "          4.5369e-02,  4.2908e-02,  7.3680e-02,  1.2795e-02, -9.0483e-03,\n",
      "          1.2679e-02, -1.6416e-02,  7.0146e-02, -2.1250e-02, -5.3487e-02,\n",
      "          2.3738e-03, -3.4668e-02,  7.4618e-02,  8.2818e-02, -8.2741e-02,\n",
      "          4.6289e-02, -5.6266e-02,  3.0896e-02, -7.4407e-02,  7.8819e-02,\n",
      "         -7.3984e-02, -6.6982e-02,  5.4686e-02,  3.4125e-03, -1.7332e-02,\n",
      "          6.0916e-02, -3.8403e-02, -4.1207e-02, -2.1172e-02,  6.0130e-02,\n",
      "         -7.3075e-02, -3.4511e-02, -4.7352e-02],\n",
      "        [ 7.5971e-02, -6.4319e-02,  4.5516e-02,  5.6746e-02, -4.8245e-02,\n",
      "         -2.5647e-02,  5.5840e-02, -8.3847e-02,  3.0620e-02,  7.3393e-02,\n",
      "         -5.6283e-02,  6.9693e-03,  3.1951e-02, -3.2673e-02,  7.7440e-02,\n",
      "         -1.9538e-02,  2.5219e-02,  3.9447e-02, -4.7357e-02, -2.7291e-02,\n",
      "         -4.8798e-03,  7.7690e-02, -6.6402e-02,  4.4602e-02,  7.4025e-02,\n",
      "          1.7829e-02, -5.3330e-02,  5.3203e-02, -7.4620e-02,  2.6359e-02,\n",
      "         -2.5396e-02, -1.4558e-02, -6.8322e-02,  1.6608e-02, -5.4638e-02,\n",
      "          8.2896e-02,  1.4523e-02, -7.4190e-02, -4.6036e-02,  5.9449e-02,\n",
      "          5.8079e-02, -3.7854e-02,  2.6471e-02,  4.0242e-02, -7.9375e-02,\n",
      "          4.1757e-02, -5.8159e-02, -2.3567e-02,  8.5046e-03,  5.6395e-02,\n",
      "         -6.3504e-02,  5.9444e-02,  4.3207e-02,  8.4366e-02, -1.1243e-02,\n",
      "         -4.9978e-03,  5.7148e-02, -8.1456e-02, -4.7364e-02, -3.0063e-02,\n",
      "         -8.1579e-02, -3.9966e-02, -7.5265e-02, -8.2342e-02, -1.2496e-02,\n",
      "          8.3402e-02,  1.6681e-02, -8.0182e-02,  2.3148e-02,  6.0943e-02,\n",
      "         -6.0154e-02,  4.9739e-02,  3.8847e-02,  1.8841e-02,  2.8951e-02,\n",
      "         -1.0393e-02, -6.9430e-02, -6.6083e-03,  6.0611e-02,  3.7404e-03,\n",
      "         -1.1266e-02, -6.3097e-02, -7.0254e-02,  4.9298e-04,  2.8903e-02,\n",
      "          6.5874e-02, -4.9118e-03,  3.4469e-02, -5.9017e-02, -8.6818e-02,\n",
      "         -5.4559e-02,  6.5480e-02, -4.6999e-02, -3.8909e-02,  2.8177e-03,\n",
      "         -4.1015e-02, -1.1415e-02, -5.6584e-02, -5.7095e-02,  8.4214e-02,\n",
      "         -8.4171e-02, -5.2638e-03,  4.0764e-02, -4.7786e-02,  3.6037e-02,\n",
      "          6.4830e-03,  7.4933e-02,  7.4979e-02,  5.8861e-04, -5.4495e-02,\n",
      "         -1.7688e-02,  4.4675e-02,  7.0122e-02,  8.9188e-03, -4.2275e-02,\n",
      "          4.5291e-02, -7.9320e-02, -7.7428e-02, -2.9660e-02, -4.3888e-02,\n",
      "         -7.5156e-02,  3.8319e-02,  7.7859e-02, -1.0102e-02,  2.5546e-02,\n",
      "          7.1662e-02, -5.6847e-02,  3.0003e-02],\n",
      "        [-6.4505e-02,  1.0197e-02, -8.0915e-03, -1.3192e-02,  6.4192e-02,\n",
      "          2.5343e-02, -7.7770e-02, -3.2139e-02, -2.6548e-02, -8.5390e-02,\n",
      "          4.1884e-02,  1.7198e-02, -6.5963e-02,  2.9162e-02, -6.7579e-02,\n",
      "          6.8925e-02, -4.9251e-02,  8.0550e-02,  1.2954e-02, -6.6716e-02,\n",
      "         -5.2750e-02,  2.8326e-02,  7.8569e-02,  5.0061e-02,  2.3087e-02,\n",
      "          4.1815e-02,  6.4752e-02,  7.9276e-02, -8.6924e-02,  9.6135e-05,\n",
      "         -5.5947e-02, -3.5123e-02, -8.7538e-02, -7.1897e-02,  5.6780e-02,\n",
      "         -1.2558e-02,  4.4908e-02, -7.3961e-02, -1.0501e-02,  6.2824e-02,\n",
      "          5.5587e-02,  7.9772e-02,  7.7223e-02, -8.0966e-02, -3.2292e-02,\n",
      "         -7.1731e-02,  6.9005e-02, -1.1992e-02, -1.2439e-02,  2.9879e-02,\n",
      "          2.5569e-02,  6.3220e-02, -2.4242e-02, -5.0565e-02,  4.1629e-02,\n",
      "         -6.4774e-02,  5.4055e-02, -1.9986e-02,  4.4606e-02, -6.1849e-02,\n",
      "         -6.1846e-02, -2.8132e-02,  6.2804e-03, -2.6975e-02,  5.9600e-02,\n",
      "          3.1557e-02,  2.7642e-02,  5.6635e-02, -7.8868e-02,  4.2814e-02,\n",
      "         -4.9209e-02,  7.8661e-02,  5.0185e-02,  3.7444e-02,  6.8373e-02,\n",
      "         -1.3277e-02, -5.9519e-02,  3.8818e-03,  4.5657e-02,  5.0229e-02,\n",
      "         -7.3569e-02, -1.2298e-02,  1.4567e-03, -3.2869e-02, -5.8539e-02,\n",
      "         -7.3029e-02,  2.3910e-03, -6.9181e-02,  2.9692e-02,  7.8229e-04,\n",
      "          1.1557e-02, -2.5661e-03,  3.3108e-02,  2.3246e-02,  1.0722e-02,\n",
      "          6.6063e-02,  6.5913e-02, -3.1544e-02,  7.7161e-02, -8.8012e-02,\n",
      "          3.3763e-04,  7.6416e-02,  8.1363e-02,  5.4600e-02,  2.2016e-02,\n",
      "         -5.3893e-02, -5.6775e-02,  1.3504e-02,  6.4136e-02,  8.4973e-03,\n",
      "          5.5658e-02,  7.0931e-02,  7.4269e-02, -3.9353e-02, -3.9244e-02,\n",
      "          7.5123e-02,  1.5534e-02,  7.6152e-02,  8.1422e-02, -8.4410e-02,\n",
      "          8.4955e-02,  1.0929e-02, -4.2051e-02,  4.7871e-02, -6.6655e-02,\n",
      "         -2.6442e-02,  6.0835e-02,  7.1854e-02]], requires_grad=True))\n",
      "('l2.bias', Parameter containing:\n",
      "tensor([-0.0777, -0.0407, -0.0233, -0.0517,  0.0441], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for parameter in net.named_parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from first_commit import makedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = makedata.MakeData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Data.input_learn\n",
    "labels = Data.output_learn\n",
    "targets = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "1\n",
      "1\n",
      "5\n",
      "4\n",
      "3\n",
      "1\n",
      "4\n",
      "5\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "2\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "1\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "2\n",
      "1\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "5\n",
      "1\n",
      "2\n",
      "4\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "1\n",
      "4\n",
      "1\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inputs)):\n",
    "    print(int(labels[i]))\n",
    "    targets = np.zeros(5)\n",
    "    targets[int(labels[i][0])-1] = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(Data.input_learn).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = torch.tensor(Data.output_learn).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test = torch.tensor(Data.input_test).float()\n",
    "# labels_test = torch.tensor(Data.output_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = Data.output_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0538, -0.2310, -0.2602, -0.1877, -0.1797], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = net(inputs[0])\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()  # 損失関数\n",
    "# loss = criterion(outputs,labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_dot(loss, params=dict(net.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習率の設定\n",
    "lr = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 5), dtype=float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = np.zeros((0,5))\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_acc, train_loss = 0, 0\n",
    "    val_acc, val_loss = 0, 0\n",
    "    n_train, n_test = 0, 0\n",
    "\n",
    "    for i in range(len(inputs)):\n",
    "        n_train += len(labels)\n",
    "\n",
    "        targets = np.zeros(5)\n",
    "        targets[int(labels[i][0])-1] = 0.99\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs[i])\n",
    "        # print(outputs)\n",
    "        targets = torch.tensor(targets).float()\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss = loss.item()\n",
    "    \n",
    "\n",
    "    for i in range(len(inputs_test)):\n",
    "        n_test += len(labels_test[i])\n",
    "\n",
    "        outputs_test = net(inputs_test[i])\n",
    "        \n",
    "        targets = np.zeros(5)\n",
    "        targets[int(labels_test[i][0])-1] = 0.99\n",
    "\n",
    "        targets = torch.tensor(targets).float()\n",
    "\n",
    "        loss_test = criterion(outputs_test, targets)\n",
    "\n",
    "        predicted_test = torch.max(outputs_test,0)[1]\n",
    "\n",
    "        val_loss += loss_test.item()\n",
    "\n",
    "        val_acc += (predicted_test == targets).sum().item()\n",
    "\n",
    "\n",
    "        history = np.vstack((history,np.array([epoch,train_loss,train_acc,val_loss,val_acc])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.79401267,  0.        ,  1.96690392,  0.        ],\n",
       "       [ 0.        ,  1.79401267,  0.        ,  3.87286186,  0.        ],\n",
       "       [ 0.        ,  1.79401267,  0.        ,  5.46300328,  0.        ],\n",
       "       ...,\n",
       "       [99.        ,  1.11006737,  0.        , 33.36652333,  4.        ],\n",
       "       [99.        ,  1.11006737,  0.        , 34.08505625,  4.        ],\n",
       "       [99.        ,  1.11006737,  0.        , 35.35706538,  4.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初期状態: 損失: 1.96690 精度: 0.00000\n"
     ]
    }
   ],
   "source": [
    "print(f\"初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最終状態: 損失: 35.35707 精度: 4.00000\n"
     ]
    }
   ],
   "source": [
    "print(f\"最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f0d15bf460>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history[:,0], history[:,2], \"b\", label=\"訓練\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
